# GPU åŠ é€Ÿå®Œæ•´é…ç½®æŒ‡å—

## ğŸ“Š å½“å‰çŠ¶æ€

### âœ… å·²å®Œæˆ
1. **ç¡¬ä»¶**: NVIDIA RTX A4000 GPU âœ“
2. **é©±åŠ¨**: NVIDIA Driver 580.95.05 âœ“
3. **CUDA**: 11.5 å·²å®‰è£… âœ“
4. **ONNX Runtime (Python)**: GPU ç‰ˆæœ¬å·²å®‰è£… âœ“
   - ç‰ˆæœ¬: 1.16.3 (æ”¯æŒ CUDA 11.x)
   - ä½ç½®: `/home/zodiac/work/tools/onnxruntime-gpu`
   - æä¾›ç¨‹åº: CUDAExecutionProvider, TensorrtExecutionProvider
5. **C++ ä»£ç **: å·²ä¿®æ”¹å¯ç”¨ CUDA âœ“

### âš ï¸ å¾…è§£å†³
1. **cuDNN ç‰ˆæœ¬ä¸åŒ¹é…**: 
   - ç³»ç»Ÿå®‰è£…: cuDNN 9.13.1
   - ONNX Runtime éœ€è¦: cuDNN 8
   - **è§£å†³æ–¹æ¡ˆ**: è§ä¸‹æ–‡

---

## ğŸ”§ è§£å†³ cuDNN ç‰ˆæœ¬é—®é¢˜

### æ–¹æ¡ˆ 1ï¼šåˆ›å»ºå…¼å®¹æ€§ç¬¦å·é“¾æ¥ï¼ˆæ¨èï¼‰

cuDNN 9 é€šå¸¸å‘åå…¼å®¹ cuDNN 8 çš„ APIï¼Œå¯ä»¥åˆ›å»ºç¬¦å·é“¾æ¥ï¼š

```bash
sudo ln -sf /usr/lib/x86_64-linux-gnu/libcudnn.so.9 /usr/lib/x86_64-linux-gnu/libcudnn.so.8
```

**éªŒè¯:**
```bash
ls -lh /usr/lib/x86_64-linux-gnu/libcudnn.so.8
```

### æ–¹æ¡ˆ 2ï¼šä½¿ç”¨ LD_LIBRARY_PATHï¼ˆæ— éœ€ sudoï¼‰

å¦‚æœæ²¡æœ‰ sudo æƒé™ï¼Œä½¿ç”¨è¿è¡Œè„šæœ¬è®¾ç½®åº“è·¯å¾„ï¼š

```bash
cd /home/zodiac/work/git/Football-Analytics-with-Deep-Learning-and-Computer-Vision/cpp
chmod +x run_with_gpu.sh
./run_with_gpu.sh --video ../test\ vid.mp4
```

è„šæœ¬ä¼šè‡ªåŠ¨é…ç½®ï¼š
- ONNX Runtime GPU åº“è·¯å¾„
- CUDA åº“è·¯å¾„
- cuDNN å…¼å®¹æ€§å¤„ç†

### æ–¹æ¡ˆ 3ï¼šç¦ç”¨ cuDNN ä½¿ç”¨çº¯ CUDAï¼ˆæ€§èƒ½ç¨å·®ï¼‰

ä¿®æ”¹ `src/YOLODetector.cpp` çš„ CUDA é…ç½®ï¼š

```cpp
OrtCUDAProviderOptions cuda_options;
cuda_options.device_id = 0;
cuda_options.cudnn_conv_algo_search = OrtCudnnConvAlgoSearchDefault;  // ä½¿ç”¨é»˜è®¤ç®—æ³•
// cuda_options.do_copy_in_default_stream = 1;  // æ³¨é‡Šæ‰æ­¤è¡Œ
```

---

## ğŸš€ é‡æ–°ç¼–è¯‘å¹¶æµ‹è¯•

### æ­¥éª¤ 1: é‡æ–°ç¼–è¯‘

```bash
cd /home/zodiac/work/git/Football-Analytics-with-Deep-Learning-and-Computer-Vision/cpp

# æ¸…ç†æ—§çš„æ„å»º
rm -rf build

# é‡æ–°æ„å»º
bash build_linux.sh
```

### æ­¥éª¤ 2: ä½¿ç”¨ GPU è¿è¡Œè„šæœ¬æµ‹è¯•

```bash
# æ–¹å¼ 1: ä½¿ç”¨è¿è¡Œè„šæœ¬ï¼ˆæ¨èï¼‰
./run_with_gpu.sh --video ../test\ vid.mp4 --player-model ../models/players.onnx

# æ–¹å¼ 2: æ‰‹åŠ¨è®¾ç½®ç¯å¢ƒå˜é‡
export LD_LIBRARY_PATH="/home/zodiac/work/tools/onnxruntime-gpu/lib:/usr/lib/x86_64-linux-gnu:${LD_LIBRARY_PATH}"
./build/football_analytics --video ../test\ vid.mp4
```

### é¢„æœŸè¾“å‡º

âœ… **æˆåŠŸçš„è¾“å‡º**:
```
Initializing ONNX Runtime...
  Model path: models/players.onnx
  Creating ONNX Runtime environment...
  Environment created successfully
  Creating session options...
  Attempting to use CUDA (GPU)...
  âœ“ CUDA provider enabled (GPU acceleration)  â† å…³é”®ï¼
  Session options configured
  Loading model file...
  Model loaded successfully
```

âŒ **å¦‚æœä»ç„¶å¤±è´¥**:
```
  âš  CUDA not available: ...
  âœ“ Falling back to CPU
```
â†’ æ£€æŸ¥åº“è·¯å¾„å’Œä¾èµ–

---

## ğŸ Python ç¯å¢ƒä¸­ä½¿ç”¨ GPU

Python ç¯å¢ƒå·²ç»é…ç½®å¥½ GPU æ”¯æŒï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ï¼š

```python
# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
cd /home/zodiac/work/git/Football-Analytics-with-Deep-Learning-and-Computer-Vision
source venv/bin/activate

# éªŒè¯ GPU æ”¯æŒ
python -c "import onnxruntime as ort; print('Available providers:', ort.get_available_providers())"

# è¾“å‡ºåº”è¯¥åŒ…å«:
# ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']
```

### åœ¨ Python ä»£ç ä¸­ä½¿ç”¨ GPU

```python
import onnxruntime as ort

# åˆ›å»ºæ¨ç†ä¼šè¯ï¼ŒæŒ‡å®šä½¿ç”¨ CUDA
session = ort.InferenceSession(
    "models/players.onnx",
    providers=['CUDAExecutionProvider', 'CPUExecutionProvider']  # CUDA ä¼˜å…ˆï¼ŒCPU ä½œä¸ºåå¤‡
)

# æ£€æŸ¥å®é™…ä½¿ç”¨çš„æä¾›ç¨‹åº
print("Using providers:", session.get_providers())
```

---

## ğŸ“ˆ æ€§èƒ½å¯¹æ¯”

| æ¨¡å¼ | FPS (é¢„ä¼°) | æ˜¾å­˜å ç”¨ | ä¼˜ç‚¹ | ç¼ºç‚¹ |
|------|-----------|---------|------|------|
| **CPU** | 5-15 | 0 GB | å…¼å®¹æ€§å¥½ | é€Ÿåº¦æ…¢ |
| **CUDA** | 50-150 | 1-2 GB | é€Ÿåº¦å¿« | éœ€è¦é…ç½® |
| **TensorRT** | 100-200 | 1-3 GB | æœ€å¿« | éœ€è¦æ¨¡å‹è½¬æ¢ |

---

## ğŸ” æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: libcublasLt.so.11 not found

```bash
# æ£€æŸ¥åº“æ˜¯å¦å­˜åœ¨
ls -lh /usr/lib/x86_64-linux-gnu/libcublasLt.so.11

# å¦‚æœä¸å­˜åœ¨ï¼Œæ·»åŠ åˆ° LD_LIBRARY_PATH
export LD_LIBRARY_PATH="/usr/lib/x86_64-linux-gnu:${LD_LIBRARY_PATH}"
```

### é—®é¢˜ 2: libcudnn.so.8 not found

```bash
# æ–¹æ¡ˆ A: åˆ›å»ºç¬¦å·é“¾æ¥ (éœ€è¦ sudo)
sudo ln -sf /usr/lib/x86_64-linux-gnu/libcudnn.so.9 /usr/lib/x86_64-linux-gnu/libcudnn.so.8

# æ–¹æ¡ˆ B: ä½¿ç”¨è¿è¡Œè„šæœ¬ (æ— éœ€ sudo)
./run_with_gpu.sh --video test.mp4
```

### é—®é¢˜ 3: CUDA provider åˆå§‹åŒ–å¤±è´¥

```bash
# æ£€æŸ¥ GPU çŠ¶æ€
nvidia-smi

# æ£€æŸ¥ CUDA ç‰ˆæœ¬
nvcc --version

# æ£€æŸ¥ ONNX Runtime åº“
ldd /home/zodiac/work/tools/onnxruntime-gpu/lib/libonnxruntime_providers_cuda.so
```

### é—®é¢˜ 4: æ˜¾å­˜ä¸è¶³

ä¿®æ”¹ `src/YOLODetector.cpp` ä¸­çš„æ˜¾å­˜é™åˆ¶ï¼š

```cpp
cuda_options.gpu_mem_limit = 1ULL * 1024 * 1024 * 1024;  // é™ä½åˆ° 1GB
```

---

## ğŸ“ å…³é”®æ–‡ä»¶æ¸…å•

```
cpp/
â”œâ”€â”€ CMakeLists.txt                 # âœ… å·²æ›´æ–°æŒ‡å‘ GPU ç‰ˆæœ¬
â”œâ”€â”€ src/YOLODetector.cpp          # âœ… å·²å¯ç”¨ CUDA
â”œâ”€â”€ run_with_gpu.sh               # âœ… GPU è¿è¡Œè„šæœ¬ï¼ˆæ–°å»ºï¼‰
â”œâ”€â”€ build_linux.sh                # æ„å»ºè„šæœ¬
â””â”€â”€ build/
    â””â”€â”€ football_analytics        # ç¼–è¯‘åçš„å¯æ‰§è¡Œæ–‡ä»¶

/home/zodiac/work/tools/
â””â”€â”€ onnxruntime-gpu/              # âœ… ONNX Runtime 1.16.3 (CUDA 11)
    â”œâ”€â”€ lib/
    â”‚   â”œâ”€â”€ libonnxruntime.so.1.16.3
    â”‚   â””â”€â”€ libonnxruntime_providers_cuda.so  # 361MB
    â””â”€â”€ include/
```

---

## âœ… å¿«é€Ÿæµ‹è¯•æ¸…å•

æ‰§è¡Œä»¥ä¸‹å‘½ä»¤éªŒè¯é…ç½®ï¼š

```bash
# 1. æ£€æŸ¥ GPU
nvidia-smi

# 2. æ£€æŸ¥ CUDA
nvcc --version

# 3. æ£€æŸ¥ Python ONNX Runtime
cd /home/zodiac/work/git/Football-Analytics-with-Deep-Learning-and-Computer-Vision
source venv/bin/activate
python -c "import onnxruntime as ort; print(ort.get_available_providers())"

# 4. åˆ›å»º cuDNN ç¬¦å·é“¾æ¥ï¼ˆéœ€è¦ä¸€æ¬¡æ€§æ‰§è¡Œï¼‰
sudo ln -sf /usr/lib/x86_64-linux-gnu/libcudnn.so.9 /usr/lib/x86_64-linux-gnu/libcudnn.so.8

# 5. é‡æ–°ç¼–è¯‘ C++ é¡¹ç›®
cd cpp
bash build_linux.sh

# 6. è¿è¡Œæµ‹è¯•
./run_with_gpu.sh --video ../test\ vid.mp4
```

---

## ğŸ’¡ æç¤º

1. **é¦–æ¬¡è¿è¡Œå¯èƒ½è¾ƒæ…¢**: CUDA éœ€è¦é¢„çƒ­å’Œ JIT ç¼–è¯‘
2. **ä½¿ç”¨ TensorRT è·å¾—æœ€ä½³æ€§èƒ½**: éœ€è¦è½¬æ¢æ¨¡å‹ä¸º `.engine` æ–‡ä»¶
3. **ç›‘æ§ GPU ä½¿ç”¨**: è¿è¡Œæ—¶ä½¿ç”¨ `watch -n 1 nvidia-smi` ç›‘æ§
4. **æ‰¹å¤„ç†ä¼˜åŒ–**: å¤„ç†å¤šä¸ªè§†é¢‘æ—¶ä¿æŒæ¨¡å‹åŠ è½½åœ¨å†…å­˜ä¸­

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [ONNX Runtime GPU å®˜æ–¹æ–‡æ¡£](https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html)
- [CUDA Toolkit æ–‡æ¡£](https://docs.nvidia.com/cuda/)
- [cuDNN æ–‡æ¡£](https://docs.nvidia.com/deeplearning/cudnn/)

---

**å¦‚æœ‰é—®é¢˜ï¼Œè¯·å‚è€ƒæœ¬æ–‡æ¡£çš„"æ•…éšœæ’æŸ¥"éƒ¨åˆ†ã€‚**
